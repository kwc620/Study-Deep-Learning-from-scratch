{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Study: Deep Learning from Scratch.ipnyb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BXBJs0b5VX3"
      },
      "source": [
        "#**Deep Learning from Scratch**\n",
        "###**Written by Steve Ive**\n",
        "https://www.github.com/steveive108\n",
        "\n",
        "This document is written basis on the book \"Deep Learning from Scratch\". The content is translated and organized basis on the book. This document is for study, so feel free to feedback and create issues and pull requests. Thx:)\n",
        "\n",
        "https://github.com/steveive108/Study-Deep-Learning-from-scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQvSUkfrlvCT"
      },
      "source": [
        "#**0. Perceptron**\n",
        "---\n",
        "The Core of Deep Learning, as an unit of each layer of deep learning\n",
        "\n",
        "- 2 input perceptron\n",
        "> y = 0 | (w1x1 + w2x2 <= thetha)\n",
        "\n",
        "  > y = 1 | (w1x1 + w2x2 > thetha)\n",
        "- Perceptron's signal can only has two value of 0 or 1\n",
        "\n",
        "- Perceptron is one kind of algorithm, that has input and output. It print specific value by stated rule from its input\n",
        "\n",
        "- Perceptron set 'weight' and 'bias' as parameter\n",
        "- Perceptron can express logic circuit such as AND, OR gate etc.\n",
        "- 1 layer Perceptron cannot express XOR gate.\n",
        "- 2 layer Perceptron can express XOR gate.\n",
        "- 1 layer Perceptron can only express linear area,  multi layer Perceptron can express non-linear area\n",
        "- multi layer Perceptron can express computer theoritically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myh4xLuRmqMA"
      },
      "source": [
        "##**0-1. 1 Layer Perceptron**\n",
        "---\n",
        "1 Layer Perceptron cannot form the XOR GATE. - the limitation of 1 layer perceptron and needness of multi-layer perceptron\n",
        "\n",
        "It can also be seen as linear function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjjXgBX5mFKp"
      },
      "source": [
        "###**AND GATE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIa2wFF9llgl"
      },
      "source": [
        "def AND(x1, x2):\n",
        "  w1, w2, theta = 0.5, 0.5, 0.7\n",
        "  tmp = x1 * w1 + x2 * w2\n",
        "  if tmp <= theta:\n",
        "    return 0\n",
        "  elif tmp > theta:\n",
        "    return 1\n",
        "\n",
        "#ADD bias and Tune to get array\n",
        "\n",
        "def AND(x1, x2):\n",
        "  x = np.array([x1, x2])\n",
        "  w = np.array([0.5, 0.5])\n",
        "  b = -0.7\n",
        "  tmp = np.sum(w*x) + b\n",
        "  if tmp <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zYinSTQm3yZ"
      },
      "source": [
        "###**NAND GATE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJetmJtAm69v"
      },
      "source": [
        "def NAND(x1, x2):\n",
        "  x = np.array([x1, x2])\n",
        "  w = np.array([-0.5, -0.5])\n",
        "  b = -0.7\n",
        "  tmp = np.sum(w*x) + b\n",
        "  if tmp <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0T-F9DUmIiG"
      },
      "source": [
        "###**OR GATE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMhZlhR7mIJq"
      },
      "source": [
        "def OR(x1, x2):\n",
        "  x = np.array([x1, x2])\n",
        "  w = np.array([0.5, 0.5])\n",
        "  b = -0.2\n",
        "  tmp = np.sum(w*x) + b\n",
        "  if tmp <= 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u28XaJF_oOqp"
      },
      "source": [
        "##**0-2. Multi Layer Perceptron**\n",
        "---\n",
        "Multi-layer perceptron can form the XOR GATE.\n",
        "\n",
        "It means that it can be seen as non-linear function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA6IjSVppHNL"
      },
      "source": [
        "###**XOR GATE**\n",
        "The combination of NAND GATE, OR GATE, AND GATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86oRXMRhofAx"
      },
      "source": [
        "def XOR(x1, x2):\n",
        "  s1 = NAND(x1, x2)\n",
        "  s2 = OR(x1, x2)\n",
        "  y = AND(s1, s2)\n",
        "  return y"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZRbZPQOtDyw"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoxoEQPyrHdM"
      },
      "source": [
        "#**1. Neural Network**\n",
        "---\n",
        "- At the neural network, we use smoothly changing function like Sigmoid function or Relu as Activation function.\n",
        "- we can implement neural network efficiently using numpy's multi dimensional array.\n",
        "- The problem of machine learning can be divided into two main parts, the \"Regression\" and \"Classification\".\n",
        "- As the output's activation function, regression tend to use 'identity function', and classification tend to use 'softmax function'.\n",
        "- At the classification, the number of output layer's neurons are set equal to the number of classes to classify.\n",
        "- A bundle of input data is called a \"batch\", we can get more fast results when we task inference in batches.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMH1jkvcrSDN"
      },
      "source": [
        "##**1-1. Activation Function**\n",
        "\n",
        "**Non Linear Function vs Linear Function**\n",
        "- Both step function and sigmoid function is 'non linear function'\n",
        "- if output change as much as input's constant, it called 'linear function'.\n",
        "- if we use linear function as activation function, it is useless to make layers deep."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zeyH9lzrO-g"
      },
      "source": [
        "###**Step Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uadCvCm9rK5w"
      },
      "source": [
        "def step_function(x):\n",
        "  if x > 0:\n",
        "    return 1\n",
        "\n",
        "#tune to get np.array\n",
        "\n",
        "def step_function(x):\n",
        "  y = x > 0\n",
        "  return y.asytpe(np.int)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5RsLxRZtoot"
      },
      "source": [
        "###**Graph of step function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "aOi4vjYTtreF",
        "outputId": "aad31f2a-0e8c-442f-a04c-2755a275e3c1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "def step_function(x):\n",
        "  return np.array(x > 0, dtype=np.int)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = step_function(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-0.1, 1.1) # range of axis y\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARQElEQVR4nO3df4wc513H8c/Hdw6hSpqo8SHAZ+dMcSWspCjVyUTkj0YkRU4INhIt2ChAIar/qVGqBpBLUFqlSKhEFIRqKAaq/qDUuOHXiToyBYKQgES+ND+Enbo6mbQ+U5RrGlKkNPhm5ssfu3deLjOza3t3557x+yVFupmd7n5Xffaj8XeeZ8YRIQBA+jY0XQAAYDgIdABoCQIdAFqCQAeAliDQAaAlJpv64E2bNsXMzExTHw8ASXrqqae+ERFTZa81FugzMzOan59v6uMBIEm2v1r1Gi0XAGgJAh0AWoJAB4CWINABoCUIdABoCQIdAFqCQAeAliDQAaAlCHQAaAkCHQBagkAHgJYg0AGgJQh0AGiJvoFu+xO2X7T97xWv2/bv2V6w/Zzttw2/TABAP4OcoX9S0q6a1++StL37335Jf3D5ZQEALlbf+6FHxD/bnqk5ZI+kT0dESHrC9vW2vycivj6kGoFGvfLqsp47999Nl4EWefPUNfre679z6O87jAdcbJZ0tmd7sbvvdYFue786Z/HaunXrED4aGL0Pf+GUHn1qseky0CK/8RM36d5bbxz6+471iUURcVjSYUmanZ2NcX42cKm+9e1l3XjDG/Tb7/rBpktBS2y94Q0jed9hBPo5SVt6tqe7+4BWyIvQtVdPanbmTU2XAtQaxrTFOUk/153tcqukV+ifo02Wi9DEBmb4Yv3re4Zu+3OSbpe0yfaipA9K2ihJEfFxScck3S1pQdKrkn5hVMUCTciLQhs3uOkygL4GmeWyr8/rIem9Q6sIWGeW89AEgY4E8O9IoI+8CE1OEOhY/wh0oI+sCE3SQ0cCGKVAH1leaJKWCxJAoAN95AU9dKSBQAf6yIrQxgl+Klj/GKVAH1lecIaOJBDoQB+di6IEOtY/Ah3og2mLSAWBDvTRWVjETwXrH6MU6CMvmLaINBDoQB8ZLRckgkAH+shyLooiDQQ60EfO7XORCEYp0EdWFNpIywUJINCBGkURKkIsLEISCHSgRlZ0Hn1LDx0pINCBGvlKoHMvFySAUQrUWC4KSZyhIw0EOlAjzztn6PTQkQICHaiR0XJBQhilQI2MlgsSQqADNTJaLkgIgQ7UWJnlwsIipIBAB2qstFxY+o8UMEqBGiwsQkoIdKDGSg+dQEcKCHSgxoVpiwQ61j8CHaiRr05b5KeC9W+gUWp7l+3TthdsHyx5favtx20/bfs523cPv1Rg/JZpuSAhfQPd9oSkQ5LukrRD0j7bO9Yc9uuSjkbELZL2Svr9YRcKNGFl2iLz0JGCQc7Qd0paiIgzEXFe0hFJe9YcE5Le2P37Okn/ObwSgeaw9B8pGWSUbpZ0tmd7sbuv14ck3Wt7UdIxSb9U9ka299uetz2/tLR0CeUC45XlLP1HOoZ12rFP0icjYlrS3ZI+Y/t17x0RhyNiNiJmp6amhvTRwOhktFyQkEEC/ZykLT3b0919ve6TdFSSIuLfJF0tadMwCgSadGHpPy0XrH+DjNITkrbb3mb7KnUues6tOeZrku6QJNs/oE6g01NB8pbzlaX/nKFj/esb6BGRSTog6bik59WZzXLS9sO2d3cPe0DSe2w/K+lzkt4dETGqooFxyVn6j4RMDnJQRBxT52Jn776Hev4+Jem24ZYGNI+VokgJjUGgxoV7ufBTwfrHKAVq5AU9dKSDQAdqZDzgAgkh0IEaPIIOKSHQgRoXHnDBTwXrH6MUqLF6+1xaLkgAgQ7UWLl97oQJdKx/BDpQIy9CGyxtoIeOBBDoQI2sCG6di2QwUoEaWV6w7B/JINCBGlkRTFlEMgh0oEZeBLfORTIYqUCNrCg4Q0cyCHSgRpYHPXQkg0AHauRFsKgIySDQgRrLRbDsH8lgpAI1cnroSAiBDtSgh46UEOhAjYweOhJCoAM1MnroSAgjFajB0n+khEAHarD0Hykh0IEaLP1HShipQI0sZ9oi0kGgAzU6F0UJdKSBQAdqsPQfKSHQgRrLecG0RSRjoJFqe5ft07YXbB+sOOanbJ+yfdL2nw23TKAZObNckJDJfgfYnpB0SNI7JC1KOmF7LiJO9RyzXdIHJN0WES/b/q5RFQyMEytFkZJBztB3SlqIiDMRcV7SEUl71hzzHkmHIuJlSYqIF4dbJtAM7uWClAwS6Jslne3ZXuzu6/UWSW+x/S+2n7C9q+yNbO+3PW97fmlp6dIqBsaos7CIHjrSMKyROilpu6TbJe2T9Ee2r197UEQcjojZiJidmpoa0kcDo5MXhTbSckEiBgn0c5K29GxPd/f1WpQ0FxHLEfEfkr6iTsADSctyLooiHYME+glJ221vs32VpL2S5tYc89fqnJ3L9iZ1WjBnhlgn0AgWFiElfQM9IjJJByQdl/S8pKMRcdL2w7Z3dw87Lukl26ckPS7pVyLipVEVDYxLZ2ERPXSkoe+0RUmKiGOSjq3Z91DP3yHp/d3/gNZYLrh9LtLBqQdQoShCEaKHjmQQ6ECFrAhJ4va5SAYjFaiQFYUkztCRDgIdqLByhk4PHakg0IEKeU6gIy0EOlBheaXlQg8diWCkAhVyWi5IDIEOVMhouSAxBDpQYfWiKDfnQiIIdKBCvjptkZ8J0sBIBSqsLiyi5YJEEOhAhZUeOguLkAoCHahADx2pIdCBCis99El66EgEIxWosMy0RSSGQAcqrC4sYqUoEsFIBSos59xtEWkh0IEKLP1Hagh0oAKzXJAaAh2ocOFeLvxMkAZGKlCBJxYhNQQ6UCFffaYogY40EOhABZb+IzUEOlDhwjNF+ZkgDYxUoMLq0n9aLkgEgQ5UYOk/UkOgAxVWLorSQ0cqBgp027tsn7a9YPtgzXE/aTtszw6vRKAZqw+44F4uSETfkWp7QtIhSXdJ2iFpn+0dJcddK+l+SU8Ou0igCRn3ckFiBjn12ClpISLORMR5SUck7Sk57sOSPiLptSHWBzQm414uSMwggb5Z0tme7cXuvlW23yZpS0R8oe6NbO+3PW97fmlp6aKLBcYpL0ITGyybQEcaLrs5aHuDpI9KeqDfsRFxOCJmI2J2amrqcj8aGKnloqDdgqQMEujnJG3p2Z7u7ltxraSbJP2T7Rck3SppjgujSF2eB+0WJGWQQD8habvtbbavkrRX0tzKixHxSkRsioiZiJiR9ISk3RExP5KKgTHJCgIdaekb6BGRSTog6bik5yUdjYiTth+2vXvUBQJNyYqCx88hKZODHBQRxyQdW7PvoYpjb7/8soDmrVwUBVLB6QdQIctDGwl0JIRABypkRWiCG3MhIQQ6UKFzUZSfCNLBaAUq5EXBLBckhUAHKiznXBRFWgh0oEJeBA+3QFIIdKACPXSkhtEKVMhyeuhIC4EOVMhouSAxBDpQoXOGzk8E6WC0AhVY+o/UEOhAhawIbaTlgoQQ6ECFjHnoSAyBDlTICnroSAujFajAwiKkhkAHKrD0H6kh0IEKOY+gQ2IIdKBCZ2ERPxGkg9EKVMi4fS4SQ6ADFXJ66EgMgQ5U6Cws4ieCdDBagQpZUXCGjqQQ6ECFjFkuSAyBDpQoilCEWCmKpDBagRLLRSFJrBRFUgh0oERehCTRQ0dSCHSgRNYNdHroSMlAgW57l+3TthdsHyx5/f22T9l+zvY/2L5x+KUC45PlBDrS0zfQbU9IOiTpLkk7JO2zvWPNYU9Lmo2It0p6VNJvDbtQYJyybg99gnnoSMggo3WnpIWIOBMR5yUdkbSn94CIeDwiXu1uPiFperhlAuO10kPfyBk6EjJIoG+WdLZne7G7r8p9kh4re8H2ftvztueXlpYGrxIYs5WWCxdFkZKh/nvS9r2SZiU9UvZ6RByOiNmImJ2amhrmRwNDtXpRlGmLSMjkAMeck7SlZ3u6u+//sX2npAclvT0i/nc45QHNyFfmobOwCAkZZLSekLTd9jbbV0naK2mu9wDbt0j6Q0m7I+LF4ZcJjNcys1yQoL6BHhGZpAOSjkt6XtLRiDhp+2Hbu7uHPSLpGkmft/2M7bmKtwOSwMIipGiQlosi4pikY2v2PdTz951Drgto1EoPndvnIiWMVqBElnfnoXOGjoQQ6EAJZrkgRQQ6UOLC0n9+IkgHoxUosbr0n5YLEkKgAyVWl/7TckFCCHSgxDJL/5EgAh0okRf00JEeRitQIuMRdEgQgQ6U4AEXSBGBDpRg6T9SRKADJVj6jxQxWoESzENHigh0oAQ9dKSIQAdKrE5bpOWChDBagRLLq08s4gwd6SDQgRI5K0WRIAIdKLF6+1wCHQkh0IESWVFoYoNlE+hIB4EOlMiKoN2C5BDoQIk8D20k0JEYAh0owRk6UkSgAyWyomAOOpLDiAVK5EUwwwXJIdCBEss5gY70EOhAibwITfBwCySGQAdKZEVoI4+fQ2IYsUCJLC+Y5YLkEOhACaYtIkUDBbrtXbZP216wfbDk9e+w/efd15+0PTPsQoFxyovgaUVIzmS/A2xPSDok6R2SFiWdsD0XEad6DrtP0ssR8f2290r6iKSfHkXBry3nem05H8VbA6u+fT7nDB3J6RvoknZKWoiIM5Jk+4ikPZJ6A32PpA91/35U0sdsOyJiiLVKkj71ry/oNx/78rDfFnidW7/vTU2XAFyUQQJ9s6SzPduLkn6o6piIyGy/IukGSd/oPcj2fkn7JWnr1q2XVPAPv3mTPvjjOy7pfwtcjJ3bCHSkZZBAH5qIOCzpsCTNzs5e0tn7zdPX6ebp64ZaFwC0wSBXfc5J2tKzPd3dV3qM7UlJ10l6aRgFAgAGM0ign5C03fY221dJ2itpbs0xc5J+vvv3OyX94yj65wCAan1bLt2e+AFJxyVNSPpERJy0/bCk+YiYk/Qnkj5je0HSN9UJfQDAGA3UQ4+IY5KOrdn3UM/fr0l613BLAwBcDFZOAEBLEOgA0BIEOgC0BIEOAC1BoANASxDoANASBDoAtASBDgAtQaADQEsQ6ADQEgQ6ALQEgQ4ALeGm7nJre0nSVxv58MuzSWuexHSFuBK/N9/5ypHS974xIqbKXmgs0FNlez4iZpuuY9yuxO/Nd75ytOV703IBgJYg0AGgJQj0i3e46QIaciV+b77zlaMV35seOgC0BGfoANASBDoAtASBfhlsP2A7bG9qupZRs/2I7S/bfs72X9m+vumaRsn2LtunbS/YPth0PaNme4vtx22fsn3S9v1N1zQutidsP237b5uu5XIR6JfI9hZJPyrpa03XMiZflHRTRLxV0lckfaDhekbG9oSkQ5LukrRD0j7bO5qtauQySQ9ExA5Jt0p67xXwnVfcL+n5posYBgL90v2OpF+VdEVcVY6Iv4uIrLv5hKTpJusZsZ2SFiLiTEScl3RE0p6GaxqpiPh6RHyp+/f/qBNwm5utavRsT0v6MUl/3HQtw0CgXwLbeySdi4hnm66lIb8o6bGmixihzZLO9mwv6goItxW2ZyTdIunJZisZi99V58SsaLqQYZhsuoD1yvbfS/rukpcelPRr6rRbWqXuO0fE33SPeVCdf55/dpy1YTxsXyPpLyS9LyK+1XQ9o2T7HkkvRsRTtm9vup5hINArRMSdZftt3yxpm6RnbUud1sOXbO+MiP8aY4lDV/WdV9h+t6R7JN0R7V7AcE7Slp7t6e6+VrO9UZ0w/2xE/GXT9YzBbZJ2275b0tWS3mj7TyPi3obrumQsLLpMtl+QNBsRqdyp7ZLY3iXpo5LeHhFLTdczSrYn1bnwe4c6QX5C0s9ExMlGCxshd85OPiXpmxHxvqbrGbfuGfovR8Q9TddyOeihY1Afk3StpC/afsb2x5suaFS6F38PSDquzsXBo20O867bJP2spB/p/v/7TPfMFQnhDB0AWoIzdABoCQIdAFqCQAeAliDQAaAlCHQAaAkCHQBagkAHgJb4PzyUJvMyloV/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75rafG0IB-dG"
      },
      "source": [
        "###**Sigmoid Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grgpSPPVCCHa"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGEH6POhCLu2"
      },
      "source": [
        "###**Graph of sigmoid function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_CJ6H1ZkCR7d",
        "outputId": "35f27209-fb1a-4695-cf81-4badd6d946a5"
      },
      "source": [
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = sigmoid(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CREidUApCnq9"
      },
      "source": [
        "###**RELU Function**\n",
        "\n",
        "h(x) = \n",
        "\n",
        "x (x > 0)\n",
        "\n",
        "0 (x <= 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1Vx_5cyDubB"
      },
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVFOISOND2oL"
      },
      "source": [
        "###**Graph of Relu Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "a_6kgnD0D7N3",
        "outputId": "3209bc95-6d3f-4d70-d07a-a18f281b4e93"
      },
      "source": [
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = relu(x)\n",
        "plt.plot(x, y)\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4GSAxeREcV4"
      },
      "source": [
        "##**1-2. Multi Dimension Array**\n",
        "if numbers are listed as one line, or rectangle or 3 dimension, further to N dimension, we call it 'Mutli Dimension Array'.\n",
        "\n",
        "- **np.ndim(Array)**: \n",
        "check the dimension of array\n",
        "\n",
        "- **Array.shape**:\n",
        "check the shape of array (**return tuple**)\n",
        "\n",
        "- **Array.shape[0]**: check amount of numbers in the first dimension(index is zero)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2jdphWhEgk-",
        "outputId": "70c02a3a-b946-406b-a055-032771d50b5e"
      },
      "source": [
        "# 1 Dimension Array\n",
        "import numpy as np\n",
        "A = np.array([1,2,3,4])\n",
        "\n",
        "np.ndim(A)\n",
        "\n",
        "A.shape\n",
        "A.shape[0]\n",
        "\n",
        "# 2 Dimension Array\n",
        "B = np.array([[1,2], [3,4], [5,6]])\n",
        "print(B)\n",
        "\n",
        "np.ndim(B)\n",
        "\n",
        "B.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAknVa2dGkQp"
      },
      "source": [
        "###**Dot Product of Matrix**\n",
        "\n",
        "- **np.dot(A, B)**: dot product of matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8gPfExFGwrt",
        "outputId": "f9010def-8b93-4011-972c-02f8a07dd7dc"
      },
      "source": [
        "# 2X2 Matrix dot product\n",
        "A = np.array([[1,2], [3,4]])\n",
        "A.shape\n",
        "\n",
        "B = np.array([[5,6], [7,8]])\n",
        "B.shape\n",
        "\n",
        "np.dot(A, B)\n",
        "\n",
        "# 3X3 Matrix dot product with 3X2 Matrix \n",
        "A = np.array([[1,2,3], [4,5,6]])\n",
        "A.shape\n",
        "B = np.array([[1,2], [3,4], [5,6]])\n",
        "B.shape\n",
        "np.dot(A, B)\n",
        "\n",
        "# 3X2 Matrix dot product with 2X1 Matrix\n",
        "A = np.array([[1,2], [3,4], [5,6]])\n",
        "A.shape\n",
        "B = np.array([7,8])\n",
        "B.shape\n",
        "np.dot(A, B)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23, 53, 83])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jn0V5aWJJkR"
      },
      "source": [
        "##**1-3. Matrix Dot Product in Neural Network**\n",
        "\n",
        "Dot Product in Neural Network can be said as 'Results indicating set of weighted sum of nodes in previous layer, each edge is one kind of Broad Casting from node to each set of weights that is indicated to the node'\n",
        "\n",
        "Or, we could say some kind of converter, which return the constraint number of output from constraint number of input with the multiplying of each weighted edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk7aTrswLrXQ",
        "outputId": "4baa99d4-2ccd-4e47-8f7e-0cf4a0335ec9"
      },
      "source": [
        "# form of X, Y, W\n",
        "\n",
        "X = np.array([1, 2])\n",
        "X.shape\n",
        "\n",
        "W = np.array([[1,3,5], [2,4,6]])\n",
        "print(W)\n",
        "\n",
        "W.shape\n",
        "Y = np.dot(X, W)\n",
        "print(Y)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 3 5]\n",
            " [2 4 6]]\n",
            "[ 5 11 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl7azlFQM-sA"
      },
      "source": [
        "##**1-4. Create 3 Layer Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr3dAHhON6t5"
      },
      "source": [
        "###**0(Input) Layer to 1 Layer**\n",
        "\n",
        " A(1) = XW(1) + B(1)\n",
        "\n",
        "Z(1) = Sigmoid(A1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPA8ebF3NONc",
        "outputId": "c775f453-a39d-4126-e46a-f9176dd871c3"
      },
      "source": [
        "X = np.array([1.0, 0.5])\n",
        "W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
        "B1 = np.array([0.1, 0.2, 0.3])\n",
        "\n",
        "print(W1.shape)\n",
        "print(X.shape)\n",
        "print(B1.shape)\n",
        "\n",
        "A1 = np.dot(X, W1) + B1"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "(2,)\n",
            "(3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0n3TL9l0Pwg"
      },
      "source": [
        "####**convert signal with sigmoid**\n",
        "\n",
        "**h(A) = Z**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr5pbcQ3N0cJ",
        "outputId": "d69a6071-fcf8-4d42-d9ca-f3decd86bc16"
      },
      "source": [
        "Z1 = sigmoid(A1)\n",
        "\n",
        "print(A1)\n",
        "print(Z1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3 0.7 1.1]\n",
            "[0.57444252 0.66818777 0.75026011]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEREt_zI0xlM"
      },
      "source": [
        "###**Layer 1 to Layer 2**\n",
        "\n",
        "A(2) = XW(2) + B(2)\n",
        "\n",
        "Z2 = Sigmoid(A(2))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iYw_tkD1hAT",
        "outputId": "c22ba437-ba5f-4e2a-b1da-df0bcc41aee8"
      },
      "source": [
        "W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "B2 = np.array([0.1, 0.2])\n",
        "\n",
        "print(Z1.shape)\n",
        "print(W2.shape)\n",
        "print(B2.shape)\n",
        "\n",
        "A2 = np.dot(Z1, W2) + B2\n",
        "Z2 = sigmoid(A2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3,)\n",
            "(3, 2)\n",
            "(2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdb8Q7xZ2PGa"
      },
      "source": [
        "###**Layer2 to output Layer**\n",
        "\n",
        "A(3) = XW(3) + B(3)\n",
        "\n",
        "Y = identity_function(A(3))\n",
        "\n",
        "- **identity function**: return output using the input as is\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-OF1Wfs3H-F",
        "outputId": "91f2f169-feb5-4666-b10c-613ea2ecd79a"
      },
      "source": [
        "def identity_function(x):\n",
        "  return x\n",
        "\n",
        "W3 = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
        "B3 = np.array([0.1, 0.2])\n",
        "\n",
        "A3 = np.dot(Z2, W3) + B3\n",
        "Y = identity_function(A3) # Y = A3\n",
        "\n",
        "print(Y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.31682708 0.69627909]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSsH6mom3oVP"
      },
      "source": [
        "##**1-5. Conclusion of 3 layer Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfm7GgdT3v4Y",
        "outputId": "9d017066-cf45-476e-94fb-67870c3a3910"
      },
      "source": [
        "def init_network():\n",
        "  network = {}\n",
        "  network['W1'] = np.array([[0.1, 0.3, 0.5], [ 0.2, 0.4, 0.5]])\n",
        "  network['b1'] = np.array([0.1, 0.2, 0.3])\n",
        "  network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
        "  network['b2'] = np.array([0.1, 0.2])\n",
        "  network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
        "  network['b3'] = np.array([0.1, 0.2])\n",
        "\n",
        "  return network\n",
        "\n",
        "def forward(network, x):\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1)\n",
        "  \n",
        "  a2 = np.dot(z1, W2) + b2\n",
        "  z2 = sigmoid(a2)\n",
        "\n",
        "  a3 = np.dot(z2, W3) + b3\n",
        "  y = identity_function(a3)\n",
        "\n",
        "  return y\n",
        "\n",
        "network = init_network()\n",
        "\n",
        "x = np.array([1.0, 0.5])\n",
        "y = forward(network, x)\n",
        "print(y)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.31655918 0.69567667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6znDgjsA88tK"
      },
      "source": [
        "##**1-6. Create OutPut Layer**\n",
        "\n",
        "Neural Network can be used in both classificiation and regression. Therefore, The activation function vary to kinds of problem. Generally, ***regression*** problem uses **identity function** as activation function, and ***classifciation*** problem uses **softmax** as activation function.\n",
        "\n",
        "> Machine learning problem consist of 'Classification', 'Regression' ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emicb-Wo-m8H"
      },
      "source": [
        "####**Identity Function and Softmax Function**\n",
        "\n",
        "- **Identity Function**: a1 -> y1\n",
        "\n",
        "- **softmax Function**: y(k) = exp( a(k) ) / sum( exp( a(i) ) \n",
        "\n",
        "> (i=1 to k)\n",
        "\n",
        "- ***Identity Function output*** nodes get signal from the **each corresponding node** of previous layer, otherwise ***softmax function output*** nodes get signal from **all nodes** of previous layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjyVrke9AdDc"
      },
      "source": [
        "####**Softmax Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVE1Dgd9-DpB",
        "outputId": "98dcfa00-6d44-45ad-97da-75de69510991"
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "\n",
        "exp_a = np.exp(a)\n",
        "print(exp_a)\n",
        "\n",
        "sum_exp_a = np.sum(exp_a)\n",
        "print(sum_exp_a)\n",
        "\n",
        "y = exp_a / sum_exp_a\n",
        "print(y)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.34985881 18.17414537 54.59815003]\n",
            "74.1221542101633\n",
            "[0.01821127 0.24519181 0.73659691]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj1nKqDKA6pu"
      },
      "source": [
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "\n",
        "  y = exp_a / sum_exp_a\n",
        "\n",
        "  return y"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMsxlHYUBcPn"
      },
      "source": [
        "####**Warning of implementing softmax function in python**\n",
        "\n",
        "When creating softmax function in python, there has a flaw called 'overflow'. softmax function is exponential function, which return the very large value. For example, exp(10) is over 20,000, exp(100) has 40 zeros, exp(1000) call 'inf' which means infinite. Also, when we divide with these large value, the result is unstable.\n",
        "\n",
        "> So we should reform the softmax function, using the max value from the input signal of softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_ZpwkmCCTEU",
        "outputId": "6121091b-9b05-4b76-f453-4c6510201219"
      },
      "source": [
        "#not functioning well\n",
        "a = np.array([1010, 1000, 990])\n",
        "np.exp(a) / np.sum(np.exp(a))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, nan, nan])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfeQhlPpCm7w",
        "outputId": "250b1d99-772e-4f7f-e72a-374dc267a535"
      },
      "source": [
        "#functioning well\n",
        "c = np.max(a)\n",
        "\n",
        "a - c\n",
        "\n",
        "np.exp(a - c) / sum(np.exp(a - c))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqgtoiUUC8tf"
      },
      "source": [
        "#re generating softmax function\n",
        "\n",
        "def softmax(a):\n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a - c)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "\n",
        "  y= exp_a / sum_exp_a\n",
        "\n",
        "  return y"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMvxoWmaDNPG"
      },
      "source": [
        "####**The Feature of softmax function**\n",
        "\n",
        "The feature of the softmax function is its sum of output is 1. This is one of the important feature of softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0qdcSY9De_P",
        "outputId": "90dc9c1d-591d-4fd1-8436-250df685012d"
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "y = softmax(a)\n",
        "print(y)\n",
        "\n",
        "np.sum(y)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.01821127 0.24519181 0.73659691]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMc00BRPEC9g"
      },
      "source": [
        "####**On the basis of this feature, We can explain softmax as \"Probability\"**\n",
        "\n",
        "- y[0]'s possibility: 0.018(1.8%)\n",
        "- y[1]'s possibility: 0.245(24.5%)\n",
        "- y[2]'s possibility: 0.737(73.7%)\n",
        "\n",
        "####**We can predict the answer is 'class 2', since the output possibility of second index is the largest.**\n",
        "\n",
        "####**For the important thing, each large-small relationship between elements does not change after adopting softmax.**\n",
        "\n",
        "> **softmax: y = exp(x) is monotic increasing function.**\n",
        "\n",
        "####**Classification using neural network generally only recognize the largest output value node. As a result, when we inference the classification task with neural network, we tend to omit the softmax generally to reduce the resource to calculate the exponential function. However, we should use softmax function when we train the neural network.**\n",
        "\n",
        "> Solving Machine learning problem goes through two stages, which are the 'Train' and 'Inference'. After training the neural network, we task inference with the unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G2ATJ2otA5X"
      },
      "source": [
        "####**Each Output's neuron indicates the corresponding class**\n",
        "\n",
        "For Example, we can create y0 to y9 node in output layer, that indicating each number 0 to 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "165-ueOqtXFZ"
      },
      "source": [
        "##**1-7. Hand digit Recognition**\n",
        "Let's build only inference task without training with pre-trained weights. \n",
        "\n",
        "The inference task is called \"Propagation\".\n",
        "\n",
        "> As same with machine learning, the deep learning also solve problem through two steps, first, train the weights with train dataset, second, at the inference step uses the trained weights to classify the input data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCTyCK4wwLKk"
      },
      "source": [
        "####**MNIST DATASET**\n",
        "> MNIST data is one of the famous dataset in machine learning that consist of hand written digit. It is used in various field from simple research to paper research. You would find mnist dataset in many image recognize paper or machine learning paper as test dataset.\n",
        "\n",
        "> MNIST dataset consist of number from 0 to 9.\n",
        "\n",
        "- 60000 train image : train the model\n",
        "- 10000 test image : evaluate the model\n",
        "\n",
        "> MNIST image data is gray scaled 28 x 28 image, which is 1 channel.\n",
        "Each pixel takes 0 to 255, with the labeled of corresponding number such as '7', '1', '0'.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO6fF-HcGi6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4275fb8f-0623-4702-e547-c305d60c5877"
      },
      "source": [
        "#load mnist dataset from mnist.py\n",
        "\n",
        "#import sys, os\n",
        "#sys.path.append(os.pardir) #set to get the file of parent directory\n",
        "%cd '/content/drive/MyDrive/'\n",
        "!pwd\n",
        "from mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True) #first takes few minuites"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSdBNayZ8BU8",
        "outputId": "d703d291-4949-4971-bef0-ebc832d44c71"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "print(x_test.shape)\n",
        "print(t_test.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n",
            "(10000, 784)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhQUw3yp-EgS"
      },
      "source": [
        "####**Show image**\n",
        "\n",
        "`flatten=True` makes image data as 1 dimension array, we should reshape it 2 dimension of 28 x 28.\n",
        "\n",
        "Also, image data that is saved of numpy should be converted PIL data object, this task is converted by `Image.fromarray()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmrpsJJa9Nly",
        "outputId": "7e677ae7-33aa-4894-a4da-c78be3a75627"
      },
      "source": [
        "import numpy as np\n",
        "from mnist import load_mnist\n",
        "from PIL import Image\n",
        "\n",
        "def img_show(img):\n",
        "  pil_img = Image.fromarray(np.uint8(img))\n",
        "  pil_img.show()\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True)\n",
        "\n",
        "img = x_train[0]\n",
        "label = t_train[0]\n",
        "print(label)#5\n",
        "\n",
        "print(img.shape)\n",
        "img = img.reshape(28, 28)\n",
        "print(img.shape)\n",
        "\n",
        "img_show(img)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "(784,)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eP_Zyl0_yrs"
      },
      "source": [
        "###**Inference MNIST with neural network**\n",
        "\n",
        "- input layer and output layer\n",
        "\n",
        "> input layer has 784 neurons (28 x 28 = 784)\n",
        "\n",
        "> output layer has 10 neurons\n",
        "\n",
        "- total 2 hidden layers\n",
        "\n",
        "> layer 1 has 50 neurons(arbitrary)\n",
        "\n",
        "> layer 2 has 100 neurons(arbitrary)\n",
        "\n",
        "- sample_weight.pkl has trained weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mH5srz1Afbd"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def get_data():\n",
        "  (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True, one_hot_label=False)\n",
        "  return x_test, t_test\n",
        "\n",
        "def init_network():\n",
        "  with open(\"sample_weight.pkl\", \"rb\") as f:\n",
        "    network = pickle.load(f)\n",
        "\n",
        "  return network\n",
        "\n",
        "def predict(network, x):\n",
        "  W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "  b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1)\n",
        "\n",
        "  a2 = np.dot(z1, W2) + b2\n",
        "  z2 = sigmoid(a2)\n",
        "\n",
        "  a3 = np.dot(z2, W3) + b3\n",
        "  y= softmax(a3)\n",
        "\n",
        "  return y"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poG9qsqMBvi5"
      },
      "source": [
        "###**Execute Inference and Check Accuracy**\n",
        "\n",
        "- get image one by one and classify by `predict()`\n",
        "- `predict()` function return each label's probability into numpy\n",
        "- select the largest probability index in array\n",
        "- compare with the answer label index with the selected index\n",
        "\n",
        "- count the accuracty_cnt and divide by the number of images in dataset.\n",
        "- Acurracy: 0.9352"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV4JhypeBvSc",
        "outputId": "95e3d68a-bf74-48b1-c1c3-0e3aea14c162"
      },
      "source": [
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "accuracy_cnt = 0\n",
        "for i in range((len(x))):\n",
        "  y = predict(network, x[i])\n",
        "  p = np.argmax(y) # select the index most largest probability\n",
        "  if p == t[i]:\n",
        "    accuracy_cnt += 1\n",
        "\n",
        "print('Accuracy:', str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4MHvj1GEMvS"
      },
      "source": [
        "###**Pre-Processing**\n",
        "\n",
        "At the `load_mnist()` we set `normalize=True`, which means that the range of each pixels which is 0 ~ 255, is converted to range of 0.0~0.1. (Divide pixels value by 255)\n",
        "\n",
        "> Like this, the processing that is converting data to specific range is called **\"Normalization**, the behavior that push specific task to input data is called **\"Pre-Processing\"** in Neural network.\n",
        "\n",
        "> Here we've done Normalize as Pre-Processing.\n",
        "\n",
        "> Neural Network uses pre-processing very frequently since the data pre-processing improves identifying ability and training speed. At the real work, it is more often to use pre-processing with considering with whole data distribution. For example, using the data's mean and standard deviation, we can shift the data either limit the range to distribute it to make center of 0. Besides, there are data \"whitening\", which is distributing whole data equally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCl4dGsGGIyq"
      },
      "source": [
        "###**Batch**\n",
        "Let's review the input data and weight parameter again pay attention to its 'shape'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVt1cULkKtWw",
        "outputId": "2f4ac10d-594c-4f10-a879-1cd2d652b420"
      },
      "source": [
        "#print the shape of weights of each layer\n",
        "\n",
        "x, _ = get_data()\n",
        "network = init_network()\n",
        "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
        "\n",
        "print(x.shape)\n",
        "print(x[0].shape)\n",
        "print(W1.shape)\n",
        "print(W2.shape)\n",
        "print(W3.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(784,)\n",
            "(784, 50)\n",
            "(50, 100)\n",
            "(100, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFf6zc0hQXek"
      },
      "source": [
        "At the result, we can find the multi dimensional array's corresponding dimension's number of elements are corresponding.\n",
        "\n",
        ">  When one image is entered\n",
        "\n",
        "> --X--------W1--------     W2-------      W2-----> Y\n",
        "\n",
        "> 784-------784x50------50x100-----100x10--------10\n",
        "\n",
        "\n",
        "> when multi images are entered (hand over 100 images at one time to `predict()` in batch) => we can express 100 images of data as one input data.\n",
        "\n",
        "> -----X---------W1--------     W2-------      W2----------> Y\n",
        "\n",
        "> 100x784-------784x50------50x100-----100x10--------100x10\n",
        "\n",
        "As we can see the shape of input data is 100x784, the shape of output data is 100x10. It means the batch of the 100 images input data's result returned at once.\n",
        "\n",
        "Like this, the data that is tied up with one set is called **'Batch'**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vabdrdbpTPuW"
      },
      "source": [
        "####**Implementing the Batch Processing**\n",
        "The marked below is the changes compared to above\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWU-8uteLdai",
        "outputId": "55f32a35-86af-4edd-8c7f-cf067c124ac8"
      },
      "source": [
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "batch_size = 100 #added\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size): #changed\n",
        "  x_batch = x[i:i+batch_size]#changed\n",
        "  y_batch = predict(network, x_batch)#changed\n",
        "  p = np.argmax(y_batch, axis = 1)#changed\n",
        "  accuracy_cnt += np.sum(p == t[i:i+batch_size])#changed\n",
        "\n",
        "print(\"Accuracy\", str(float(accuracy_cnt) / len(x)))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.9352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXsStGP0MeyP"
      },
      "source": [
        "To help understanding of `p = np.argmax(y_batch, axis = 1)` and `np.sum(p == t[i:i+batch_size])`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaVJDeb0MoR9",
        "outputId": "364057fa-8e85-4c89-ed4a-90171391ad13"
      },
      "source": [
        "x = np.array([[1.0, 0.8, 0.1], [0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.8, 0.1, 0.1]])\n",
        "\n",
        "y = np.argmax(x, axis = 1)\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 2 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcLWcNdgM5wT",
        "outputId": "78842b5c-695b-433e-ad90-3035c0497b3f"
      },
      "source": [
        "y = np.array([1, 2, 1, 0])\n",
        "t = np.array([1, 2, 0, 0])\n",
        "print(y == t)\n",
        "\n",
        "np.sum(y == t)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True False  True]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBlCMXYuO0kx"
      },
      "source": [
        "##**Conclusion**\n",
        "\n",
        "Here, we looked up the neural network's forward propagation. The neural network in this chapter is same with the perceptron in the feature of each layers' neuron propagating the signal to the next layer's neurons. However there were big difference of **Activation Function** through the signal propagates to next neuron. We used neural network's activation function as Sigmoid that is smoothly changing, on the other hand, at the perceptron we used activation function as Step function, which is suddenly changing.\n",
        "\n",
        "---\n",
        "- At the neural network, we use smoothly changing function like Sigmoid function or Relu as Activation function.\n",
        "- we can implement neural network efficiently using numpy's multi dimensional array.\n",
        "- The problem of machine learning can be divided into two main parts, the \"Regression\" and \"Classification\".\n",
        "- As the output's activation function, regression tend to use 'identity function', and classification tend to use 'softmax function'.\n",
        "- At the classification, the number of output layer's neurons are set equal to the number of classes to classify.\n",
        "- A bundle of input data is called a \"batch\", we can get more fast results when we task inference in batches.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn-G6aXiQBiI"
      },
      "source": [
        "#**2. Training Neural Network**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4_IbBp0USw7"
      },
      "source": [
        "def sum_squares_error(y, t):\n",
        "  return 0.5 * np.sum((y - t)**2)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwDXvIr8VI5R",
        "outputId": "2f0e3042-fff3-4a38-c896-dae33415e06f"
      },
      "source": [
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print(sum_squares_error(np.array(y), np.array(t)))\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(sum_squares_error(np.array(y), np.array(t)))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-r84cKbWFYl"
      },
      "source": [
        "def cross_entropy_error(y, t):\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t*np.log(y+delta))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVGqitZWWP28",
        "outputId": "8923f0e4-5ead-4a4c-e75b-50da8b572d47"
      },
      "source": [
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))\n",
        "\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(cross_entropy_error(np.array(y), np.array(t)))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4YKb_PGWnmI",
        "outputId": "668bac70-45db-4084-afd1-51008633198d"
      },
      "source": [
        "#import sys, os\n",
        "#sys.path.append(os.pardir)\n",
        "import numpy as np\n",
        "from mnist import load_mnist #from dataset.mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_y_x6O2XFOV"
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDGNH_NjXfy0",
        "outputId": "2582956d-705e-4b39-b426-012acc2764b9"
      },
      "source": [
        "#To help understanding mini batching\n",
        "np.random.choice(60000, 10)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14042, 32130, 50888, 45485, 15815, 56148,   373,   312, 48673,\n",
              "       27216])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_aDOjGOXnzn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}